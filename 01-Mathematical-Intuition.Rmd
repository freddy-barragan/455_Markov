# Mathematical Intuition

Markov Chains are cool! And Hidden Markov Models are even cooler! So, let's make sure you can get at the cool-stuff by starting off with the necessary basics. In this section, we'll review conditional probabilities & set up the basis for Hidden Markov Models by getting comfortable with chains first.

## Conditional Probability & Bayes Rule

Probability, as a field, formalizes how we predict events with some equally beautiful & ugly notation, sharp concepts, and complex mathematical principles. 
But the premise is simple: by ascribing a numeric value to the outcomes of an event happening, we can abstract the real-world and study it with math. This process of ascribing numeric values to the outcome of an event is called a mapping & by mapping all possible outcomes of an event we create a *random variable*.

> **NOTE:** This can be confusing! The "random" part of the word doesn't mean all outcomes have an equal chance of happening, really it means that within an event there are multiple possible outcomes.

For example, let's say that the weather can either be sunny, rainy, or cloudy. We can then say that the weather is an event, $W$, with the outcomes $w_s,w_r,w_c$, respectively. However, by specifying the probabilities of each event we can turn $W$ into a random variable:

$$\begin{aligned} 
p_{(W)}(w)  &= \begin{cases}
    0.5, & \text{for } w_s \\
    0.3, & \text{for } w_r \\
    0.2, & \text{for } w_c \\
    0.0, & \text{otherwise}
\end{cases}
\end{aligned}$$

But what happens when the weather changes because of temperature, implying that weather is conditional on the outcome of temperature. Let's formalize 

 + Definition of Conditional Probability
 + Definition of Bayes rule
 
## Markov Chains & The Markov Property

**Markov Property**

**Markov Chains**

+ State Space
+ Transition Probabilities & Matrices
   
   
**Visualizing a Markov Chain**
   - Will Hipson's [Dot Visualization](https://willhipson.netlify.app/post/markov-sim/markov_chain/) 
   
```{r}
library(tidyverse)
library(wesanderson)
library(plotly)
set.seed(200322)
markov2 <- function(n = 10, iter = 15, start_probs = c(.5, .2, .3), 
                    trans_probs = matrix(c(.3, .1, .7, 
                                           .2, .5, .2,
                                           .5, .4, .1), ncol = 3),
                    plot_prob = TRUE) { # Here we have a full non-zero transition matrix.
  #Check to see if probability entries are valid.
  if(sum(start_probs) != 1 | any(start_probs < 0)) 
    stop("start_probs must be non-negative and sum to 1.")
  if(any(apply(trans_probs, 1, sum) != 1))
    stop("trans_probs matrix rows must sum to 1.")
  if(any(trans_probs < 0))
    stop("elements of trans_probs must be non-negative")

  dt <- matrix(NA, nrow = iter, ncol = n) # Initialize matrix to hold iterations
  # Run chain
  for(i in 1:iter) {
    for(j in 1:n) {
      if(i == 1) { # if we're at the beginning of the simulation
        dt[i, j] <- sample(x = c(0, 1, 2), size = 1, prob = start_probs)
      } else {
        if(dt[i - 1, j] == 0) { # if the previous state was 0
          dt[i, j] <- sample(x = c(0, 1, 2), size = 1, prob = trans_probs[,1])
        } else if (dt[i - 1, j] == 1) { # if the previous state was 1
          dt[i, j] <- sample(x = c(0, 1, 2), size = 1, prob = trans_probs[,2])
        } else {
          dt[i, j] <- sample(x = c(0, 1, 2), size = 1, prob = trans_probs[,3])
        }
      }
    }
  }
  
  # Return chain as dataframe
  return(as.data.frame(dt))
}

df2 <- markov2()


df_long2 <- df2 %>%
  rowid_to_column(var = "iter") %>%
  pivot_longer(cols = V1:V10) %>%
  group_by(name) %>%
  mutate(x = value + rnorm(1, 0, .10) + rnorm(n(), 0, .01),
         y = value %% 2 + rnorm(1, 0, .10) + rnorm(n(), 0, .01),
         initial = value[1],
         is_0 = ifelse(value == 0, TRUE, FALSE),
         is_1 = ifelse(value == 1, TRUE, FALSE)) %>%
  group_by(iter) %>%
  mutate(prop0 = mean(is_0),
         prop1 = mean(is_1),
         prop2 = 1 - prop0 - prop1) %>%
  ungroup()

anim2 <- df_long2 %>%
  plot_ly(
    x = ~x,
    y = ~y,
    color = ~factor(initial),
    size = 5,
    colors =as.vector(wes_palette("GrandBudapest2", n=3, type="discrete")),
    frame = ~iter,
    type = 'scatter',
    mode = 'markers',
    showlegend = FALSE
  )

anim2 <- anim2 %>%
  add_text(x = 0, y = .35, text = ~prop0, textfont = list(color = "#E6A0C4", size = 24, opacity = .6)) %>%
  add_text(x = 1, y = 1.25, text = ~prop1, textfont = list(color = "#C6CDF7", size = 24, opacity = .6)) %>%
  add_text(x = 2, y = .35, text = ~prop2, textfont = list(color = "#D8A499", size = 24, opacity = .6))

ax2 <- list(
  zeroline = FALSE,
  showline = FALSE,
  showticklabels = FALSE,
  showgrid = FALSE,
  title = ""
)

anim2 <- anim2 %>%
  layout(xaxis = ax2, yaxis = ax2) %>%
  animation_opts(redraw = FALSE) %>%
  animation_slider(hide = TRUE) %>%
  animation_button(x = .6, y = .10, showactive = FALSE, label = "Run Simulation") %>%
  config(displayModeBar = FALSE, scrollZoom = FALSE, showTips = FALSE)
  
anim2


```

   
   - embedding [Victor Powell's Website](https://setosa.io/markov/index.html#%7B%22tm%22%3A%5B%5B0.5%2C0.5%5D%2C%5B0.5%2C0.5%5D%5D%7D).
   
 
## Video Resources

<iframe width="373" height="210" src="https://www.youtube.com/embed/VCyJGp6Enxg" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>  
<iframe width="373" height="210" src="https://www.youtube.com/embed/JHwyHIz6a8A" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>  
   

<br>
<br>

---


**References**

Hipson, Will. 2020. “Visualizing A Markov Chain.” Will Hipson’s Personal Website. March 23, 2020. https://willhipson.netlify.app/post/markov-sim/markov_chain/.

Johnson, Alicia, Miles Ott, and Mine Dogucu. 2020. “Bayes’ Rule.” In  Bayes Rules! An Introduction to Bayesian Modeling with R . https://www.bayesrulesbook.com.

Kang, Eugine. 2017. “Hidden Markov Model.” Medium. August 31, 2017. https://medium.com/@kangeugine/hidden-markov-model-7681c22f5b9.

Lay, David C. 2012. “Applications to Markov Chains.” In Linear Algebra and Its Applications, 4th ed., 253–62. Boston: Pearson College Division.

Powell, Victor, and Lewis Lehe. 2014. “Markov Chains Explained Visually.” Explained Visually. November 7, 2014. https://setosa.io/ev/markov-chains/.
 